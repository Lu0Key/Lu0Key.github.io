<!doctype html>
<html lang="en-us">
  <head>
    <title>阿里文生视频大模型试用(text-to-video-synthesis) // 洛七的摸鱼池塘</title>
    <link rel="shortcut icon" href="/favicon.ico" />
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.81.0" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="洛七" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="/css/main.min.0fb49e70a30412f97ddfc418e18fefef1d9fcdebe45f634dbbba768b00fe1eec.css" />
    

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="阿里文生视频大模型试用(text-to-video-synthesis)"/>
<meta name="twitter:description" content="阿里文本生成视频大模型试用 用的是阿里的文本生成视频大模型，地址
运行环境下载
# 用的python 3.9 conda create -n t2vtest python=3.9 conda activate t2vtest pip install modelscope==1.4.2 pip install open_clip_torch pip install pytorch-lightning # modelscope.pipelines.multi_modal.text_to_video_synthesis_pipeline requires the opencv library but it was not found in your environment. # 解决方法 pip install opencv-python addict==2.4.0 aiohttp==3.9.3 aiosignal==1.3.1 aliyun-python-sdk-core==2.15.0 aliyun-python-sdk-kms==2.16.2 async-timeout==4.0.3 attrs==23.2.0 certifi==2024.2.2 cffi==1.16.0 charset-normalizer==3.3.2 crcmod==1.7 cryptography==42.0.5 datasets==2.8.0 dill==0.3.6 einops==0.7.0 filelock==3.13.1 frozenlist==1.4.1 fsspec==2024.2.0 ftfy==6.1.3 gast==0.5.4 huggingface-hub==0.21.4 idna==3.6 importlib_metadata==7.0.2 Jinja2==3.1.3 jmespath==0.10.0 jsonplus==0.8.0 lightning-utilities==0.10.1 MarkupSafe==2.1.5 modelscope==1."/>

    <meta property="og:title" content="阿里文生视频大模型试用(text-to-video-synthesis)" />
<meta property="og:description" content="阿里文本生成视频大模型试用 用的是阿里的文本生成视频大模型，地址
运行环境下载
# 用的python 3.9 conda create -n t2vtest python=3.9 conda activate t2vtest pip install modelscope==1.4.2 pip install open_clip_torch pip install pytorch-lightning # modelscope.pipelines.multi_modal.text_to_video_synthesis_pipeline requires the opencv library but it was not found in your environment. # 解决方法 pip install opencv-python addict==2.4.0 aiohttp==3.9.3 aiosignal==1.3.1 aliyun-python-sdk-core==2.15.0 aliyun-python-sdk-kms==2.16.2 async-timeout==4.0.3 attrs==23.2.0 certifi==2024.2.2 cffi==1.16.0 charset-normalizer==3.3.2 crcmod==1.7 cryptography==42.0.5 datasets==2.8.0 dill==0.3.6 einops==0.7.0 filelock==3.13.1 frozenlist==1.4.1 fsspec==2024.2.0 ftfy==6.1.3 gast==0.5.4 huggingface-hub==0.21.4 idna==3.6 importlib_metadata==7.0.2 Jinja2==3.1.3 jmespath==0.10.0 jsonplus==0.8.0 lightning-utilities==0.10.1 MarkupSafe==2.1.5 modelscope==1." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://Lu0key.github.io/post/ali-text2video-lm/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2024-03-10T20:17:49&#43;08:00" />
<meta property="article:modified_time" content="2024-03-10T20:17:49&#43;08:00" />



  </head>
  <body>
    <header class="app-header">
      <a href="https://Lu0key.github.io/"><img class="app-header-avatar" src="/avatar.jpg" alt="洛七" /></a>
      <span class="app-header-title">洛七的摸鱼池塘</span>
      <nav class="app-header-menu">
          <a class="app-header-menu-item" href="/tags/">Tags</a>
      </nav>
      <p>即将没书读的咸鱼</p>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">阿里文生视频大模型试用(text-to-video-synthesis)</h1>
      <div class="post-meta">
        <div>
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Mar 10, 2024
        </div>
        <div>
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          1 min read
        </div>
        <div>
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tag">
  <title>tag</title>
  <path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7.01" y2="7"></line>
</svg>
              <a class="tag" href="https://Lu0key.github.io/tags/python/">Python</a>
              <a class="tag" href="https://Lu0key.github.io/tags/llm/">LLM</a>
        </div>
      </div>
    </header>
    <div class="post-content">
      <h2 id="阿里文本生成视频大模型试用">阿里文本生成视频大模型试用</h2>
<p>用的是阿里的文本生成视频大模型，<a href="https://modelscope.cn/models/iic/text-to-video-synthesis/summary">地址</a></p>
<p>运行环境下载</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># 用的python 3.9</span>
conda create -n t2vtest python<span style="color:#f92672">=</span>3.9
conda activate t2vtest
pip install modelscope<span style="color:#f92672">==</span>1.4.2
pip install open_clip_torch
pip install pytorch-lightning

<span style="color:#75715e"># modelscope.pipelines.multi_modal.text_to_video_synthesis_pipeline requires the opencv library but it was not found in your environment.</span>
<span style="color:#75715e"># 解决方法</span>
pip install opencv-python
</code></pre></div><!-- raw HTML omitted -->
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">addict==2.4.0
aiohttp==3.9.3
aiosignal==1.3.1
aliyun-python-sdk-core==2.15.0
aliyun-python-sdk-kms==2.16.2
async-timeout==4.0.3
attrs==23.2.0
certifi==2024.2.2
cffi==1.16.0
charset-normalizer==3.3.2
crcmod==1.7
cryptography==42.0.5
datasets==2.8.0
dill==0.3.6
einops==0.7.0
filelock==3.13.1
frozenlist==1.4.1
fsspec==2024.2.0
ftfy==6.1.3
gast==0.5.4
huggingface-hub==0.21.4
idna==3.6
importlib_metadata==7.0.2
Jinja2==3.1.3
jmespath==0.10.0
jsonplus==0.8.0
lightning-utilities==0.10.1
MarkupSafe==2.1.5
modelscope==1.4.2
mpmath==1.3.0
multidict==6.0.5
multiprocess==0.70.14
networkx==3.2.1
numpy==1.23.5
nvidia-cublas-cu12==12.1.3.1
nvidia-cuda-cupti-cu12==12.1.105
nvidia-cuda-nvrtc-cu12==12.1.105
nvidia-cuda-runtime-cu12==12.1.105
nvidia-cudnn-cu12==8.9.2.26
nvidia-cufft-cu12==11.0.2.54
nvidia-curand-cu12==10.3.2.106
nvidia-cusolver-cu12==11.4.5.107
nvidia-cusparse-cu12==12.1.0.106
nvidia-nccl-cu12==2.19.3
nvidia-nvjitlink-cu12==12.4.99
nvidia-nvtx-cu12==12.1.105
open-clip-torch==2.24.0
opencv-python==4.9.0.80
oss2==2.18.4
packaging==23.pytorch-lightning
pandas==2.2.1
pillow==10.2.0
platformdirs==4.2.0
protobuf==4.25.3
pyarrow==15.0.1
pycparser==2.21
pycryptodome==3.20.0
python-dateutil==2.9.0.post0
pytorch-lightning==2.2.1
pytz==2024.1
PyYAML==6.0.1
regex==2023.12.25
requests==2.31.0
responses==0.18.0
safetensors==0.4.2
scipy==1.12.0
sentencepiece==0.2.0
simplejson==3.19.2
six==1.16.0
sortedcontainers==2.4.0
sympy==1.12
timm==0.9.16
tomli==2.0.1
torch==2.2.1
torchmetrics==1.3.1
torchvision==0.17.1
tqdm==4.66.2
triton==2.2.0
typing_extensions==4.10.0
tzdata==2024.1
urllib3==2.2.1
wcwidth==0.2.13
xxhash==3.4.1
yapf==0.40.2
yarl==1.9.4
zipp==3.17.0
</code></pre></div><!-- raw HTML omitted -->
<p>这里下载模型到目录 <code>text-to-video-synthesis</code> 下, 然后就可以用下面的代码测试了.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> modelscope.pipelines <span style="color:#f92672">import</span> pipeline
<span style="color:#f92672">from</span> modelscope.outputs <span style="color:#f92672">import</span> OutputKeys

<span style="color:#f92672">import</span> time

start_time <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()

p <span style="color:#f92672">=</span> pipeline(<span style="color:#e6db74">&#39;text-to-video-synthesis&#39;</span>, <span style="color:#e6db74">&#39;text-to-video-synthesis&#39;</span>)
test_text <span style="color:#f92672">=</span> {
        <span style="color:#e6db74">&#39;text&#39;</span>: <span style="color:#e6db74">&#39;A engineer is on a video call with the interviewer.&#39;</span>,
    }
output_video_path <span style="color:#f92672">=</span> p(test_text, output_video<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;./interviewer.mp4&#39;</span>)[OutputKeys<span style="color:#f92672">.</span>OUTPUT_VIDEO]
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;output_video_path:&#39;</span>, output_video_path)

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Time:&#39;</span>, time<span style="color:#f92672">.</span>time() <span style="color:#f92672">-</span> start_time)
</code></pre></div><p>遇到了一些抽象的问题, 不知道为什么之前A服务器上的可以用, 然后到B服务器上配置的时候就用不了了, 用的是modelscope提供的git下载, 应该是下载的内容坏了, 但是坏的很一致, 不知道为什么, 删了又下, 两次的 md5 值都是一样的. 最后解决方案就是从 A 服务器上把模型下载下来, 然后上传到 B 服务器上, 就OK了&hellip;</p>
<p>不过这个模型效果一般, 玩玩, 了解一下还行.</p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
