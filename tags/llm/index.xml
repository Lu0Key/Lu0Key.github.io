<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM on 洛七的摸鱼池塘</title>
    <link>https://Lu0key.github.io/tags/llm/</link>
    <description>Recent content in LLM on 洛七的摸鱼池塘</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 10 Mar 2024 22:26:32 +0800</lastBuildDate><atom:link href="https://Lu0key.github.io/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Paddlespeech 语音识别</title>
      <link>https://Lu0key.github.io/post/paddlespeech-asr/</link>
      <pubDate>Sun, 10 Mar 2024 22:26:32 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/paddlespeech-asr/</guid>
      <description>PaddleSpeech ASR 安装
conda create -n paddlespeech python=3.10 conda activate paddlespeech # 下载依赖 pip install -r requirements.txt # 内容见下文 # 下载PadlleSpeech git clone https://github.com/PaddlePaddle/PaddleSpeech.git cd PaddleSpeech # 对于到我写这一篇博客的当前版本来说，不用这个版本会报错，虽然其他会不会我不知道，但是这个不会 # 当前版本似乎要指定模型 git checkout 1b8ca706d6a8e0a8b97ee21d93314a245d777a69 pip install . # 下载 Paddlepaddle pip install paddlepaddle==2.6.0 -i https://mirror.baidu.com/pypi/simple # 下载测试音频 wget -c https://paddlespeech.bj.bcebos.com/PaddleAudio/zh.wav requirements.txt 的内容如下:
absl-py==2.0.0 aiohttp==3.9.1 aiosignal==1.3.1 aistudio-sdk==0.1.5 annotated-types==0.6.0 antlr4-python3-runtime==4.9.3 anyio==4.2.0 astor==0.8.1 asttokens==2.4.1 async-timeout==4.0.3 attrs==23.2.0 audioread==3.0.1 Babel==2.14.0 backcall==0.2.0 bce-python-sdk==0.8.99 blinker==1.7.0 bokeh==3.1.1 boltons==23.1.1 Bottleneck==1.3.7 braceexpand==0.</description>
    </item>
    
    <item>
      <title>Openai的Whisper语音转文字试用</title>
      <link>https://Lu0key.github.io/post/openai-whisper/</link>
      <pubDate>Sun, 10 Mar 2024 20:26:19 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/openai-whisper/</guid>
      <description>openai whisper 试用 conda create -n ow python=3.9 conda activate ow pip install git+https://github.com/openai/whisper.git@ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab 按照上面的安装即可, 然后就OK了, 安装后的环境状态如下.
certifi==2024.2.2 charset-normalizer==3.3.2 filelock==3.13.1 fsspec==2024.2.0 idna==3.6s Jinja2==3.1.3 Levenshtein==0.25.0 llvmlite==0.42.0 MarkupSafe==2.1.5 more-itertools==10.2.0 mpmath==1.3.0 networkx==3.2.1 numba==0.59.0 numpy==1.26.4 nvidia-cublas-cu12==12.1.3.1 nvidia-cuda-cupti-cu12==12.1.105 nvidia-cuda-nvrtc-cu12==12.1.105 nvidia-cuda-runtime-cu12==12.1.105 nvidia-cudnn-cu12==8.9.2.26 nvidia-cufft-cu12==11.0.2.54 nvidia-curand-cu12==10.3.2.106 nvidia-cusolver-cu12==11.4.5.107 nvidia-cusparse-cu12==12.1.0.106 nvidia-nccl-cu12==2.19.3 nvidia-nvjitlink-cu12==12.3.101 nvidia-nvtx-cu12==12.1.105 openai-whisper @ git+https://github.com/openai/whisper.git@ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab python-Levenshtein==0.25.0 rapidfuzz==3.6.1 regex==2023.12.25 requests==2.31.0 sympy==1.12 tiktoken==0.6.0 torch==2.2.1 tqdm==4.66.2 triton==2.2.0 typing_extensions==4.10.0 urllib3==2.2.1 以下是测试脚本.
import whisper import time import os audio_name = &amp;#34;1.wav&amp;#34; model_type = &amp;#34;base&amp;#34; model = whisper.</description>
    </item>
    
    <item>
      <title>阿里文生视频大模型试用(text-to-video-synthesis)</title>
      <link>https://Lu0key.github.io/post/ali-text2video-lm/</link>
      <pubDate>Sun, 10 Mar 2024 20:17:49 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/ali-text2video-lm/</guid>
      <description>阿里文本生成视频大模型试用 用的是阿里的文本生成视频大模型，地址
运行环境下载
# 用的python 3.9 conda create -n t2vtest python=3.9 conda activate t2vtest pip install modelscope==1.4.2 pip install open_clip_torch pip install pytorch-lightning # modelscope.pipelines.multi_modal.text_to_video_synthesis_pipeline requires the opencv library but it was not found in your environment. # 解决方法 pip install opencv-python 安装好后的 requirements
addict==2.4.0 aiohttp==3.9.3 aiosignal==1.3.1 aliyun-python-sdk-core==2.15.0 aliyun-python-sdk-kms==2.16.2 async-timeout==4.0.3 attrs==23.2.0 certifi==2024.2.2 cffi==1.16.0 charset-normalizer==3.3.2 crcmod==1.7 cryptography==42.0.5 datasets==2.8.0 dill==0.3.6 einops==0.7.0 filelock==3.13.1 frozenlist==1.4.1 fsspec==2024.2.0 ftfy==6.1.3 gast==0.5.4 huggingface-hub==0.21.4 idna==3.6 importlib_metadata==7.0.2 Jinja2==3.1.3 jmespath==0.10.0 jsonplus==0.8.0 lightning-utilities==0.</description>
    </item>
    
  </channel>
</rss>
