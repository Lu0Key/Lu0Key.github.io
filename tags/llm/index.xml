<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM on 洛七的摸鱼池塘</title>
    <link>https://Lu0key.github.io/tags/llm/</link>
    <description>Recent content in LLM on 洛七的摸鱼池塘</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 10 Mar 2024 20:26:19 +0800</lastBuildDate><atom:link href="https://Lu0key.github.io/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Openai的Whisper语音转文字试用</title>
      <link>https://Lu0key.github.io/post/openai-whisper/</link>
      <pubDate>Sun, 10 Mar 2024 20:26:19 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/openai-whisper/</guid>
      <description>openai whisper 试用 conda create -n ow python=3.9 conda activate ow pip install git+https://github.com/openai/whisper.git@ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab 按照上面的安装即可, 然后就OK了, 安装后的环境状态如下.
certifi==2024.2.2 charset-normalizer==3.3.2 filelock==3.13.1 fsspec==2024.2.0 idna==3.6s Jinja2==3.1.3 Levenshtein==0.25.0 llvmlite==0.42.0 MarkupSafe==2.1.5 more-itertools==10.2.0 mpmath==1.3.0 networkx==3.2.1 numba==0.59.0 numpy==1.26.4 nvidia-cublas-cu12==12.1.3.1 nvidia-cuda-cupti-cu12==12.1.105 nvidia-cuda-nvrtc-cu12==12.1.105 nvidia-cuda-runtime-cu12==12.1.105 nvidia-cudnn-cu12==8.9.2.26 nvidia-cufft-cu12==11.0.2.54 nvidia-curand-cu12==10.3.2.106 nvidia-cusolver-cu12==11.4.5.107 nvidia-cusparse-cu12==12.1.0.106 nvidia-nccl-cu12==2.19.3 nvidia-nvjitlink-cu12==12.3.101 nvidia-nvtx-cu12==12.1.105 openai-whisper @ git+https://github.com/openai/whisper.git@ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab python-Levenshtein==0.25.0 rapidfuzz==3.6.1 regex==2023.12.25 requests==2.31.0 sympy==1.12 tiktoken==0.6.0 torch==2.2.1 tqdm==4.66.2 triton==2.2.0 typing_extensions==4.10.0 urllib3==2.2.1 以下是测试脚本.
import whisper import time import os audio_name = &amp;#34;1.wav&amp;#34; model_type = &amp;#34;base&amp;#34; model = whisper.</description>
    </item>
    
    <item>
      <title>阿里文生视频大模型试用(text-to-video-synthesis)</title>
      <link>https://Lu0key.github.io/post/ali-text2video-lm/</link>
      <pubDate>Sun, 10 Mar 2024 20:17:49 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/ali-text2video-lm/</guid>
      <description>阿里文本生成视频大模型试用 用的是阿里的文本生成视频大模型，地址
运行环境下载
# 用的python 3.9 conda create -n t2vtest python=3.9 conda activate t2vtest pip install modelscope==1.4.2 pip install open_clip_torch pip install pytorch-lightning # modelscope.pipelines.multi_modal.text_to_video_synthesis_pipeline requires the opencv library but it was not found in your environment. # 解决方法 pip install opencv-python 安装好后的 requirements
addict==2.4.0 aiohttp==3.9.3 aiosignal==1.3.1 aliyun-python-sdk-core==2.15.0 aliyun-python-sdk-kms==2.16.2 async-timeout==4.0.3 attrs==23.2.0 certifi==2024.2.2 cffi==1.16.0 charset-normalizer==3.3.2 crcmod==1.7 cryptography==42.0.5 datasets==2.8.0 dill==0.3.6 einops==0.7.0 filelock==3.13.1 frozenlist==1.4.1 fsspec==2024.2.0 ftfy==6.1.3 gast==0.5.4 huggingface-hub==0.21.4 idna==3.6 importlib_metadata==7.0.2 Jinja2==3.1.3 jmespath==0.10.0 jsonplus==0.8.0 lightning-utilities==0.</description>
    </item>
    
  </channel>
</rss>
