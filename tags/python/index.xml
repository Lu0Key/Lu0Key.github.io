<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on 洛七的摸鱼池塘</title>
    <link>https://Lu0key.github.io/tags/python/</link>
    <description>Recent content in Python on 洛七的摸鱼池塘</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 01 Apr 2024 10:32:46 +0800</lastBuildDate><atom:link href="https://Lu0key.github.io/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>DDP 多卡训练样例代码</title>
      <link>https://Lu0key.github.io/post/example-code-for-multi-gpu-training-using-ddp/</link>
      <pubDate>Mon, 01 Apr 2024 10:32:46 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/example-code-for-multi-gpu-training-using-ddp/</guid>
      <description>有时候训练模型为了提高速度，单纯的提高batch size 已经没用了, 这时候我们会使用多卡训练，这里我们使用DDP（Distributed Data Parallel）来实现多卡训练。
这里是单机多卡, 毕竟我们集群上也没几台机器&amp;hellip;
DDP 比较麻烦, 因此这里记录一下如何使用DDP进行多卡训练。
# 这里只是一个大致的样例，具体的代码需要根据实际情况进行修改 # 有些常见的包我也不写了 import torch.distributed as dist from torch.nn.parallel import DistributedDataParallel as DDP parser = argparse.ArgumentParser(description=&amp;#34;PyTorch DDP Example&amp;#34;) # 这个是我的习惯, 常常是为了适配单卡和多卡的场景 parser.add_argument(&amp;#34;--is_multi_gpu&amp;#34;, type=bool, default=False) # 下面这个是必要的, 这个参数不需要手动传入 parser.add_argument(&amp;#34;--local-rank&amp;#34;, type=int, default=-1) args = parser.parse_args() device = torch.device(&amp;#34;cuda&amp;#34; if torch.cuda.is_available() else &amp;#34;cpu&amp;#34;)# 指定gpu0为主GPU is_multi_gpu = args.is_multi_gpu # 后面全是用这种方式去进行适配单卡和多卡 if is_multi_gpu == True: device = args.local_rank torch.cuda.set_device(args.local_rank) dist.init_process_group(backend=&amp;#39;nccl&amp;#39;) # 首先加载数据集 train_dataset = .</description>
    </item>
    
    <item>
      <title>生成截图并写入文档</title>
      <link>https://Lu0key.github.io/post/generate-screenshots-and-write-documents/</link>
      <pubDate>Wed, 20 Mar 2024 17:46:08 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/generate-screenshots-and-write-documents/</guid>
      <description>遇到了一个很抽象的需求，需要把测试的截图放到文档里, 但是截图可能有快上万张，太逆天了，截图截一辈子. 好在截图的内容比较固定, 都是纯文字，并且背景也是固定的，因此可以直接根据文本内容生成截图，再把生成的图片流式放到文档里，这样就不用截图了，而且也不用担心截图的数量了。
因此我们通过以下几步来实现这个需求：
 生成截图的文本(这个与本次无关) 生成图片 把图片放到文档里  环境
python-docx=1.1.0 pillow=10.2.0 1. 生成图片 图片分成两部分: 文字和背景。先将思路，后再给出所有代码
1.1 生成背景 from PIL import Image, ImageDraw # 因为本来背景颜色就是纯色的 # 所以zhijietobfgu image = Image.new(&amp;#39;RGB&amp;#39;, (image_width, image_height), background_color) 1.2 生成文字 首先需要字体, 因为是对控制台的截图, VSCODE的默认字体是Consolas, 因此我们也使用这个字体
font_path = r&amp;#39;Consolas.ttf&amp;#39; # 替换为实际的字体文件路径 #　这个　font_size 对应了中文的宽度 # 这里之所以设置成50这么大, 是为了之后保证图片的分辨率不会太小. font_size = 50 font = ImageFont.truetype(font_path, font_size) 有了字体我们要设计图片的大小，之前真实的截图每次不超过7行，基本最多是6行或者7行, 因此
# 基础配置 text_color = (51, 51, 51) # 背景颜色 background_color = (253, 246, 227) # 设置图片大小 # 这里是根据一个中文, 因为我的场景是中英文混合，中文的宽度比英文大，并且中文的宽度是固定的 # 因此这里我以中文的宽度为基准，设置图片的宽度，其中第一个乘的40是预设一行中文最多40个字 # 加40是一个冗余，我们要模拟真实截图，因此起点不可能是0，而是有一定的间距, 并且是随机的， # 末尾也是一样，因此这里加40 image_width = font.</description>
    </item>
    
    <item>
      <title>Paddlespeech 语音识别与语音合成</title>
      <link>https://Lu0key.github.io/post/paddlespeech/</link>
      <pubDate>Sun, 10 Mar 2024 22:26:32 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/paddlespeech/</guid>
      <description>PaddleSpeech ASR 安装
conda create -n paddlespeech python=3.10 conda activate paddlespeech # 下载依赖 pip install -r requirements.txt # 内容见下文 # 下载PadlleSpeech git clone https://github.com/PaddlePaddle/PaddleSpeech.git cd PaddleSpeech # 对于到我写这一篇博客的当前版本来说，不用这个版本会报错，虽然其他会不会我不知道，但是这个不会 # 当前版本似乎要指定模型 git checkout 1b8ca706d6a8e0a8b97ee21d93314a245d777a69 pip install . # 下载 Paddlepaddle pip install paddlepaddle==2.6.0 -i https://mirror.baidu.com/pypi/simple # 如果要用GPU就用下面的版本 # python -m pip install paddlepaddle-gpu==2.6.0 -i https://pypi.tuna.tsinghua.edu.cn/simple # 下载测试音频 wget -c https://paddlespeech.bj.bcebos.com/PaddleAudio/zh.wav absl-py==2.0.0 aiohttp==3.9.1 aiosignal==1.3.1 aistudio-sdk==0.1.5 annotated-types==0.6.0 antlr4-python3-runtime==4.9.3 anyio==4.2.0 astor==0.8.1 asttokens==2.4.1 async-timeout==4.0.3 attrs==23.2.0 audioread==3.</description>
    </item>
    
    <item>
      <title>Openai的Whisper语音转文字试用</title>
      <link>https://Lu0key.github.io/post/openai-whisper/</link>
      <pubDate>Sun, 10 Mar 2024 20:26:19 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/openai-whisper/</guid>
      <description>openai whisper 试用 conda create -n ow python=3.9 conda activate ow pip install git+https://github.com/openai/whisper.git@ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab certifi==2024.2.2 charset-normalizer==3.3.2 filelock==3.13.1 fsspec==2024.2.0 idna==3.6s Jinja2==3.1.3 Levenshtein==0.25.0 llvmlite==0.42.0 MarkupSafe==2.1.5 more-itertools==10.2.0 mpmath==1.3.0 networkx==3.2.1 numba==0.59.0 numpy==1.26.4 nvidia-cublas-cu12==12.1.3.1 nvidia-cuda-cupti-cu12==12.1.105 nvidia-cuda-nvrtc-cu12==12.1.105 nvidia-cuda-runtime-cu12==12.1.105 nvidia-cudnn-cu12==8.9.2.26 nvidia-cufft-cu12==11.0.2.54 nvidia-curand-cu12==10.3.2.106 nvidia-cusolver-cu12==11.4.5.107 nvidia-cusparse-cu12==12.1.0.106 nvidia-nccl-cu12==2.19.3 nvidia-nvjitlink-cu12==12.3.101 nvidia-nvtx-cu12==12.1.105 openai-whisper @ git+https://github.com/openai/whisper.git@ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab python-Levenshtein==0.25.0 rapidfuzz==3.6.1 regex==2023.12.25 requests==2.31.0 sympy==1.12 tiktoken==0.6.0 torch==2.2.1 tqdm==4.66.2 triton==2.2.0 typing_extensions==4.10.0 urllib3==2.2.1 以下是测试脚本.
import whisper import time import os audio_name = &amp;#34;1.wav&amp;#34; model_type = &amp;#34;base&amp;#34; model = whisper.load_model(model_type) print(model.</description>
    </item>
    
    <item>
      <title>阿里文生视频大模型试用(text-to-video-synthesis)</title>
      <link>https://Lu0key.github.io/post/ali-text2video-lm/</link>
      <pubDate>Sun, 10 Mar 2024 20:17:49 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/ali-text2video-lm/</guid>
      <description>阿里文本生成视频大模型试用 用的是阿里的文本生成视频大模型，地址
运行环境下载
# 用的python 3.9 conda create -n t2vtest python=3.9 conda activate t2vtest pip install modelscope==1.4.2 pip install open_clip_torch pip install pytorch-lightning # modelscope.pipelines.multi_modal.text_to_video_synthesis_pipeline requires the opencv library but it was not found in your environment. # 解决方法 pip install opencv-python {% details 按照上面的安装即可, 然后就OK了, 安装后的环境状态如下. %}
addict==2.4.0 aiohttp==3.9.3 aiosignal==1.3.1 aliyun-python-sdk-core==2.15.0 aliyun-python-sdk-kms==2.16.2 async-timeout==4.0.3 attrs==23.2.0 certifi==2024.2.2 cffi==1.16.0 charset-normalizer==3.3.2 crcmod==1.7 cryptography==42.0.5 datasets==2.8.0 dill==0.3.6 einops==0.7.0 filelock==3.13.1 frozenlist==1.4.1 fsspec==2024.2.0 ftfy==6.1.3 gast==0.5.4 huggingface-hub==0.21.4 idna==3.6 importlib_metadata==7.</description>
    </item>
    
    <item>
      <title>检测服务器状态</title>
      <link>https://Lu0key.github.io/post/detect-server-status/</link>
      <pubDate>Wed, 28 Feb 2024 17:14:54 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/detect-server-status/</guid>
      <description>检测服务器状态脚本
主打一个抽象, 代码如下:
from flask import Flask, request, redirect, url_for, session, render_template import psutil import subprocess app = Flask(__name__) app.secret_key = &amp;#39;keyyyyy&amp;#39; # 设置一个随机的密钥来加密 session 数据 def get_cpu_usage(): # 显示cpu型号 return &amp;#39;{}%&amp;#39;.format(psutil.cpu_percent(interval=1)) def bytes_to_gb(bytes): return bytes / (1024 ** 3) def get_mem_usage(): return &amp;#39;{:.2f}/{} GB({}%)&amp;#39;.format(bytes_to_gb(psutil.virtual_memory().used), int(bytes_to_gb(psutil.virtual_memory().total)), psutil.virtual_memory().percent) def get_gpu_info(): try: result = subprocess.run([&amp;#39;nvidia-smi&amp;#39;, &amp;#39;--query-gpu=index,name,memory.total,memory.used,memory.free,utilization.gpu,utilization.memory&amp;#39;, &amp;#39;--format=csv,noheader,nounits&amp;#39;], capture_output=True, text=True).stdout.strip() except Exception as e: if &amp;#34;No such file or directory: &amp;#39;nvidia-smi&amp;#39;&amp;#34; in str(e): return {&amp;#39;id&amp;#39;:[&amp;#39;无显卡&amp;#39;], &amp;#39;gpu_mem_usage&amp;#39;: [], &amp;#39;gpu_utilization&amp;#39;: []} else: print(e) return {&amp;#39;id&amp;#39;:[&amp;#39;未知显卡错误&amp;#39;], &amp;#39;gpu_mem_usage&amp;#39;: [], &amp;#39;gpu_utilization&amp;#39;: []} # print(result) if &amp;#34;NVIDIA-SMI has failed &amp;#34; in result: return {&amp;#39;id&amp;#39;:[&amp;#39;显卡驱动异常&amp;#39;], &amp;#39;gpu_mem_usage&amp;#39;: [&amp;#39;N/A&amp;#39;], &amp;#39;gpu_utilization&amp;#39;: [&amp;#39;N/A&amp;#39;]} elif &amp;#34;Unable to determine the device handle&amp;#34; in result: return {&amp;#39;id&amp;#39;:[&amp;#39;显卡状态异常&amp;#39;], &amp;#39;gpu_mem_usage&amp;#39;: [&amp;#39;N/A&amp;#39;], &amp;#39;gpu_utilization&amp;#39;: [&amp;#39;N/A&amp;#39;]} else: gpu_info = result.</description>
    </item>
    
    <item>
      <title>Images to UByte</title>
      <link>https://Lu0key.github.io/post/images-to-ubyte/</link>
      <pubDate>Thu, 30 Mar 2023 18:41:44 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/images-to-ubyte/</guid>
      <description>图片数据集合转化为MNIST的UByte.gz格式 因为要使用别人的模型，替换成自己的数据集，但是发现别人的模型用的是MNIST一个t10k-labels-idx1-ubyte 这样名字的数据集，而不是直接的图片，因此为了避免麻烦，我想要把自己的图片数据集转化为这种格式的，找了半天在Github 上找到了，这里只是记录一下，方便下次用
# https://blog.csdn.net/ycc2011/article/details/88965606 # # This python script converts a sample of the notMNIST dataset into # the same file format used by the MNIST dataset. If you have a program # that uses the MNIST files, you can run this script over notMNIST to # produce a new set of data files that should be compatible with # your program. # # Instructions: # # 1) if you already have a MNIST data/ directory, rename it and create # a new one # # $ mv data data.</description>
    </item>
    
    <item>
      <title>科学上网爬虫</title>
      <link>https://Lu0key.github.io/post/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E7%88%AC%E8%99%AB/</link>
      <pubDate>Mon, 09 Jan 2023 01:47:56 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E7%88%AC%E8%99%AB/</guid>
      <description>有时候会有需求需要爬需要科学上网才能访问的网站，但是如果开全局模式，访问正常网站就会非常慢，因此需要开PAC模式，但是PAC模式似乎不能直接用 requests 发送请求。
找了半天，最后发现了PAC模式支持的方式，代码如下
from pypac import PACSession,get_pac url = &amp;#39;https://xxxxxx.com&amp;#39; # 这个 url 是要看你的科学上网软件来着的 pac = get_pac(url=&amp;#39;http://127.0.0.1:端口/pac/?t=164907&amp;#39;) s = PACSession(pac) #解析pac文件 resp = s.get(url, headers=headers) </description>
    </item>
    
    <item>
      <title>RGBA图像直接叠加</title>
      <link>https://Lu0key.github.io/post/rgba%E5%9B%BE%E5%83%8F%E7%9B%B4%E6%8E%A5%E5%8F%A0%E5%8A%A0/</link>
      <pubDate>Sun, 08 Jan 2023 01:38:02 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/rgba%E5%9B%BE%E5%83%8F%E7%9B%B4%E6%8E%A5%E5%8F%A0%E5%8A%A0/</guid>
      <description>因为在做图像补全任务时,想要展示缺陷图像的样子,需要将背景透明的mask图像加到原图像上,生成需要补全的图像.
原本的mask长这样
原本的图像长这样
预期的图片长这样
省流版: img.alpha_composite(mask)
我们发现背景是黑色的,一开始想的是创建一个新的图片,和目标图像一样大小,使用mask.getpixel((i,j)) 去获取mask每一个像素点,然后如果获取的黑色的,那就设置新图的像素为原图的像素newImg.putpixel((i,j),originImg.getpixel((i,j))),大概这个思路,因为原图是没有通道的,可能要简单的修改. 之前试过,这个方法是可行的,但是速度太慢了,我要对上百张图片进行这个操作要好久,所以去找别的方法.
首先我希望把mask盖到原图像上,就像PS一样,透明的部分不会印象下面的内容.因此我先把不透明的mask转化成透明的,因为mask是通用的,所以一张图片的效率低可以接受,以下是代码和效果.
mask = Image.open(&amp;#34;mask.png&amp;#34;) W, H = mask.size newMask = Image.new(&amp;#34;RGBA&amp;#34;, mask.size, (0, 0, 0, 0)) for i in range(W): for j in range(H): # print(mask.getpixel((i, j))) if mask.getpixel((i, j)) == (255, 255, 255): newMask.putpixel((i, j), (255, 255, 255, 255)) newMask.save(&amp;#34;newMask.png&amp;#34;)  这里才知道 img.size 返回的是先是宽度,然后才是高
getpixel((i,j)), 这里的i和j也分别是宽的位置和高的位置.
 得到了新的mask
希望把newMask直接盖到原图像上,查了半天,网上要么是一个个像素去判断的,效率难以接受,要么是用Image.blend(image,mask,alpha),这种方法会改变原图像的透明度,效果如此公式:
$$\text{image} * (1-\text{alpha})+\text{mask} * \text{alpha}$$
truthImg = Image.open(os.path.join(basepath, &amp;#34;truth&amp;#34;, imgName)) newImg = Image.</description>
    </item>
    
    <item>
      <title>Python 下载图片</title>
      <link>https://Lu0key.github.io/post/python-download-img/</link>
      <pubDate>Sun, 11 Jul 2021 00:23:25 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/python-download-img/</guid>
      <description>在做Python 爬虫的时候，爬取图片是一个很常用的功能
# 主要部分代码 with open(filename, &amp;#34;wb&amp;#34;) as f: f.write(resp.content) 比较通用的下载图片代码
def download_img(url,src,count=0): &amp;#34;&amp;#34;&amp;#34; :param url: 图片地址 :param src: 图片存放的文件夹 :param count: 调用次数，默认为 0 &amp;#34;&amp;#34;&amp;#34; resp = requests.get(url,headers=headers) filename = src + &amp;#34;\\&amp;#34;+ url.split(&amp;#34;/&amp;#34;)[-1] # 判断文件夹存不存在 if not os.path.exists(src): os.makedirs(src) if not os.path.isdir(src): os.makedirs(src) try: # 主要部分 with open(filename, &amp;#34;wb&amp;#34;) as f: f.write(resp.content) resp.close() except: print(&amp;#34;============================================&amp;#34;) print(&amp;#34;Error:&amp;#34;, filename) resp.close() if count&amp;lt;5: download_img(url,src,count+1) else: print(&amp;#34;彻底失败&amp;#34;) </description>
    </item>
    
    <item>
      <title>Python 爬虫乱码问题</title>
      <link>https://Lu0key.github.io/post/python-crawler-mistaken-code/</link>
      <pubDate>Sat, 10 Jul 2021 23:23:46 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/python-crawler-mistaken-code/</guid>
      <description>import requests headers = { &amp;#34;User-Agent&amp;#34;:&amp;#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0&amp;#34; } resp = requests.get(&amp;#34;http://cmathc.cn/&amp;#34;, headers=headers) print(resp.text) 可以很明显看出有乱码，解决的方式非常的简单粗暴
我们发现，网络返回的字符集类型和推测出来的字符集类型是不一致的，因此我们只要将字符集类型设定为推断出来的字符集类型即可，于是
import requests headers = { &amp;#34;User-Agent&amp;#34;:&amp;#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0&amp;#34; } resp = requests.get(&amp;#34;http://cmathc.cn/&amp;#34;, headers=headers) resp.encoding = resp.apparent_encoding print(resp.text) 看图可知乱码问题得到了解决</description>
    </item>
    
    <item>
      <title>Python Selenium 笔记</title>
      <link>https://Lu0key.github.io/post/python-selenium/</link>
      <pubDate>Sun, 28 Feb 2021 19:30:33 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/python-selenium/</guid>
      <description>Python Selenium 笔记 这里用的是Firefox的 webdriver
browser = webdriver.Firefox(executable_path =r&amp;#34;D:\geckodriver&amp;#34;) 通过get打开网页
browser.get(&amp;#34;https://www.baidu.com&amp;#34;) 窗口最大化
browser.maximize_window() 输入内容
browser.find_element_by_id(&amp;#34;un&amp;#34;).send_keys(&amp;#34;学号&amp;#34;) 点击事件
browser.find_element_by_id(&amp;#34;index_login_btn&amp;#34;).click() close 和 quit 的区别
# close 是关闭当前tab browser.close() # quit 是关闭整个浏览器 browser.quit() 在自动化操作的时候可能会遇到多个标签页，这里我还不是很清楚，一个标签页对应一个句柄
# 获得所有句柄 handles = browser.window_handles # 获得当前句柄 currentWin = browser.current_window_handle 因为我在使用的时候，最多只会遇到两个标签页，多的标签页可以直接close掉，因此没有深究怎么切换到指定的标签页的方法，只要每次产生新的标签页的时候，我就把当前的标签页关掉，然后获得新标签页的句柄(因为只有一个标签页，因此句柄也只有一个)
# 假装这里打开了新的标签页 # 关闭当前标签页 browser.close() # 获得所有句柄(这时只有1个) handles = browser.window_handles # 切换到这个句柄上 browser.switch_to.window(handles[0]) 当页面中有iframe标签的时候，选择器无法选择到iframe中的内容，因此要切换到iframe内
# 这里只要获得了对应的iframe标签即可，比如用id也可以 iframe = browser.find_elements_by_tag_name(&amp;#34;iframe&amp;#34;)[0] # 切换到iframe中就可以用css选择器之类的去获取元素 browser.switch_to.frame(iframe) # 对iframe中的内容操作完了，返回原页面 browser.switch_to.default_content() </description>
    </item>
    
    <item>
      <title>Python 操作 Excel</title>
      <link>https://Lu0key.github.io/post/python-wr-excel/</link>
      <pubDate>Sun, 28 Feb 2021 18:37:37 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/python-wr-excel/</guid>
      <description>Python 处理excel 老师需要找出哪些同学在网上填了返校申请，因为有几百个人，所以比较难以肉眼看出来
这里我们假设填了信息的人可以导出名字，和整个年级的名单
这样我们就有两个表了，代码如下
import xlrd # 总的人名 name_set = [] # 填报的人 name_data = [] # 没填报的人 other = [] set_excel = xlrd.open_workbook(&amp;#39;C:\\Users\\Luokey\\Desktop\\set.xlsx&amp;#39;) set_sheet = set_excel.sheets()[0] print(set_sheet.name) print(&amp;#34;=============&amp;#34;) # 这里实际上是从第二行开始，到第一列的最后一个元素 for i in range(1,len(set_sheet.col_slice(0, start_rowx=0, end_rowx=None))): name = set_sheet.cell_value(i, 0) name_set.append(name) print(name_set) print(len(name_set)) data_excel = xlrd.open_workbook(&amp;#39;C:\\Users\\Luokey\\Desktop\\data.xlsx&amp;#39;) data_sheet = data_excel.sheets()[0] print(&amp;#34;=============&amp;#34;) # 这里实际上是从第二行开始，到第一列的最后一个元素 for i in range(1,len(data_sheet.col_slice(0, start_rowx=0, end_rowx=None))): name = data_sheet.cell_value(i, 0) name_data.append(name) print(&amp;#34;======没提交的名单=======&amp;#34;) for name in name_set: if name not in name_data: print(name) other.</description>
    </item>
    
    <item>
      <title>Python Flask 入门</title>
      <link>https://Lu0key.github.io/post/python-flask-%E5%85%A5%E9%97%A8/</link>
      <pubDate>Fri, 22 Jan 2021 16:01:50 +0800</pubDate>
      
      <guid>https://Lu0key.github.io/post/python-flask-%E5%85%A5%E9%97%A8/</guid>
      <description>Flask  Flask  特点 list  example   tuple(元组)  “可变的” tuple  tips     循环  range() continue  example   break   dict set  常用函数   定义函数  tips 空函数 参数检查 多个返回值 默认参数  坑   可变参数 关键字参数 命名关键词参数   参数组合还没看&amp;hellip;..  递归函数  tips   尾递归 切片 Slice 切片   Iteration 迭代  如何判断一个对象是否可迭代 如何同时迭代索引和元素   列表生成式 generator 生成器 迭代器 高阶函数 map/reduce filter sorted 返回函数 闭包(Closure) 匿名函数lambda 装饰器(Decorator) 偏函数 Partial function 模块 Module  作用域 安装第三方库   OOP 访问限制 继承和多态 获取对象信息 实例属性和类属性 使用__slots__ 使用@property 多重继承 定制类  __iter__ __getattr__ __call__   枚举类 待解决问题    特点 123</description>
    </item>
    
  </channel>
</rss>
